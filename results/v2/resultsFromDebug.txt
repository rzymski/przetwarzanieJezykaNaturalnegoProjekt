D:\programowanie\python\przetwarzanieJezykaNaturalnego\projekt\.venv\Scripts\python.exe D:\programowanie\python\przetwarzanieJezykaNaturalnego\projekt\main.py 
馃攧 Rozpoczynanie wczytywania dokument贸w treningowych i testowych...
馃搨 Rozpoczynanie wczytywania dokument贸w z folderu: dataProcessed/train\neg
鉁旓笍 Wczytano maksymaln膮 liczb臋 plik贸w (1000) z folderu: dataProcessed/train\neg
馃搨 Rozpoczynanie wczytywania dokument贸w z folderu: dataProcessed/train\pos
鉁旓笍 Wczytano maksymaln膮 liczb臋 plik贸w (1000) z folderu: dataProcessed/train\pos
鉁旓笍 Wczytano wszystkie dokumenty (艂膮cznie: 2000).
馃搨 Rozpoczynanie wczytywania dokument贸w z folderu: dataProcessed/test\neg
鉁旓笍 Wczytano maksymaln膮 liczb臋 plik贸w (1000) z folderu: dataProcessed/test\neg
馃搨 Rozpoczynanie wczytywania dokument贸w z folderu: dataProcessed/test\pos
鉁旓笍 Wczytano maksymaln膮 liczb臋 plik贸w (1000) z folderu: dataProcessed/test\pos
鉁旓笍 Wczytano wszystkie dokumenty (艂膮cznie: 2000).
馃敡 Rozpoczynanie obliczania macierzy TF-IDF...
鉁?Obliczono macierz TF-IDF.
馃棏锔?Usuni臋to istniej膮cy plik: trainingMatrix.csv
馃捑 Zapisuj臋 macierz do pliku trainingMatrix.csv w partiach po 1000 wierszy...
鉁?Zapisano wiersze od 0 do 1000.
鉁?Zapisano wiersze od 1000 do 2000.
馃棏锔?Usuni臋to istniej膮cy plik: testMatrix.csv
馃捑 Zapisuj臋 macierz do pliku testMatrix.csv w partiach po 1000 wierszy...
鉁?Zapisano wiersze od 0 do 1000.
鉁?Zapisano wiersze od 1000 do 2000.

========== Training and Evaluating LinearSVC with params {'C': 0.5, 'max_iter': 1000, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 0.5, 'max_iter': 1000, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      0.98      0.99      1000
    Positive       0.98      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.86      0.85      1000
    Positive       0.86      0.84      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating LinearSVC with params {'C': 0.5, 'max_iter': 1000, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 0.5, 'max_iter': 1000, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.85      0.84      1000
    Positive       0.85      0.82      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating LinearSVC with params {'C': 0.5, 'max_iter': 100, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 0.5, 'max_iter': 100, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      0.98      0.99      1000
    Positive       0.98      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.86      0.85      1000
    Positive       0.86      0.84      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating LinearSVC with params {'C': 0.5, 'max_iter': 100, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 0.5, 'max_iter': 100, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.85      0.84      1000
    Positive       0.85      0.82      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating LinearSVC with params {'C': 0.5, 'max_iter': 10000, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 0.5, 'max_iter': 10000, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      0.98      0.99      1000
    Positive       0.98      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.86      0.85      1000
    Positive       0.86      0.84      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating LinearSVC with params {'C': 0.5, 'max_iter': 10000, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 0.5, 'max_iter': 10000, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.85      0.84      1000
    Positive       0.85      0.82      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating LinearSVC with params {'C': 1.0, 'max_iter': 1000, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 1.0, 'max_iter': 1000, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.84      0.82      1000
    Positive       0.84      0.80      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 1.0, 'max_iter': 1000, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 1.0, 'max_iter': 1000, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.82      0.84      0.83      1000
    Positive       0.83      0.81      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 1.0, 'max_iter': 100, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 1.0, 'max_iter': 100, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.84      0.82      1000
    Positive       0.84      0.80      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 1.0, 'max_iter': 100, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 1.0, 'max_iter': 100, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.82      0.84      0.83      1000
    Positive       0.83      0.81      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 1.0, 'max_iter': 10000, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 1.0, 'max_iter': 10000, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.84      0.82      1000
    Positive       0.83      0.80      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 1.0, 'max_iter': 10000, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 1.0, 'max_iter': 10000, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.82      0.84      0.83      1000
    Positive       0.83      0.81      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 2.0, 'max_iter': 1000, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 2.0, 'max_iter': 1000, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.81

Classification Report:
              precision    recall  f1-score   support

    Negative       0.80      0.83      0.81      1000
    Positive       0.82      0.79      0.81      1000

    accuracy                           0.81      2000
   macro avg       0.81      0.81      0.81      2000
weighted avg       0.81      0.81      0.81      2000


========== Training and Evaluating LinearSVC with params {'C': 2.0, 'max_iter': 1000, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 2.0, 'max_iter': 1000, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.83      0.82      1000
    Positive       0.83      0.80      0.81      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 2.0, 'max_iter': 100, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 2.0, 'max_iter': 100, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.81

Classification Report:
              precision    recall  f1-score   support

    Negative       0.80      0.83      0.81      1000
    Positive       0.82      0.79      0.81      1000

    accuracy                           0.81      2000
   macro avg       0.81      0.81      0.81      2000
weighted avg       0.81      0.81      0.81      2000


========== Training and Evaluating LinearSVC with params {'C': 2.0, 'max_iter': 100, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 2.0, 'max_iter': 100, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.83      0.82      1000
    Positive       0.83      0.80      0.81      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating LinearSVC with params {'C': 2.0, 'max_iter': 10000, 'loss': 'hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 2.0, 'max_iter': 10000, 'loss': 'hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.81

Classification Report:
              precision    recall  f1-score   support

    Negative       0.80      0.83      0.81      1000
    Positive       0.82      0.79      0.81      1000

    accuracy                           0.81      2000
   macro avg       0.81      0.81      0.81      2000
weighted avg       0.81      0.81      0.81      2000


========== Training and Evaluating LinearSVC with params {'C': 2.0, 'max_iter': 10000, 'loss': 'squared_hinge'} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LinearSVC trained successfully with parameters: {'C': 2.0, 'max_iter': 10000, 'loss': 'squared_hinge'}

Evaluation on Training Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (LinearSVC):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.83      0.82      1000
    Positive       0.83      0.80      0.81      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.90

Classification Report:
              precision    recall  f1-score   support

    Negative       0.92      0.88      0.90      1000
    Positive       0.89      0.92      0.91      1000

    accuracy                           0.90      2000
   macro avg       0.90      0.90      0.90      2000
weighted avg       0.90      0.90      0.90      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.80

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.77      0.79      1000
    Positive       0.78      0.82      0.80      1000

    accuracy                           0.80      2000
   macro avg       0.80      0.80      0.80      2000
weighted avg       0.80      0.80      0.80      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.88

Classification Report:
              precision    recall  f1-score   support

    Negative       0.89      0.87      0.88      1000
    Positive       0.87      0.90      0.88      1000

    accuracy                           0.88      2000
   macro avg       0.88      0.88      0.88      2000
weighted avg       0.88      0.88      0.88      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.78

Classification Report:
              precision    recall  f1-score   support

    Negative       0.78      0.78      0.78      1000
    Positive       0.78      0.77      0.78      1000

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.87

Classification Report:
              precision    recall  f1-score   support

    Negative       0.89      0.84      0.86      1000
    Positive       0.85      0.90      0.87      1000

    accuracy                           0.87      2000
   macro avg       0.87      0.87      0.87      2000
weighted avg       0.87      0.87      0.87      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.78

Classification Report:
              precision    recall  f1-score   support

    Negative       0.80      0.74      0.77      1000
    Positive       0.76      0.82      0.79      1000

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.94

Classification Report:
              precision    recall  f1-score   support

    Negative       0.96      0.93      0.94      1000
    Positive       0.93      0.96      0.95      1000

    accuracy                           0.94      2000
   macro avg       0.95      0.95      0.94      2000
weighted avg       0.95      0.94      0.94      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.82      0.81      0.82      1000
    Positive       0.82      0.82      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.93

Classification Report:
              precision    recall  f1-score   support

    Negative       0.96      0.90      0.93      1000
    Positive       0.91      0.96      0.93      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.81

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.77      0.80      1000
    Positive       0.79      0.86      0.82      1000

    accuracy                           0.81      2000
   macro avg       0.82      0.81      0.81      2000
weighted avg       0.82      0.81      0.81      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.93

Classification Report:
              precision    recall  f1-score   support

    Negative       0.95      0.91      0.93      1000
    Positive       0.92      0.96      0.94      1000

    accuracy                           0.93      2000
   macro avg       0.94      0.93      0.93      2000
weighted avg       0.94      0.93      0.93      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.78      0.81      1000
    Positive       0.80      0.85      0.82      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.84      0.84      1000
    Positive       0.84      0.83      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.83

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.82      0.83      1000
    Positive       0.83      0.83      0.83      1000

    accuracy                           0.83      2000
   macro avg       0.83      0.83      0.83      2000
weighted avg       0.83      0.83      0.83      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.83

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.80      0.83      1000
    Positive       0.81      0.86      0.84      1000

    accuracy                           0.83      2000
   macro avg       0.83      0.83      0.83      2000
weighted avg       0.83      0.83      0.83      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.91

Classification Report:
              precision    recall  f1-score   support

    Negative       0.92      0.90      0.91      1000
    Positive       0.90      0.92      0.91      1000

    accuracy                           0.91      2000
   macro avg       0.91      0.91      0.91      2000
weighted avg       0.91      0.91      0.91      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.81

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.79      0.81      1000
    Positive       0.80      0.84      0.82      1000

    accuracy                           0.81      2000
   macro avg       0.81      0.81      0.81      2000
weighted avg       0.81      0.81      0.81      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.92

Classification Report:
              precision    recall  f1-score   support

    Negative       0.92      0.92      0.92      1000
    Positive       0.92      0.92      0.92      1000

    accuracy                           0.92      2000
   macro avg       0.92      0.92      0.92      2000
weighted avg       0.92      0.92      0.92      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.81

Classification Report:
              precision    recall  f1-score   support

    Negative       0.81      0.83      0.82      1000
    Positive       0.82      0.80      0.81      1000

    accuracy                           0.81      2000
   macro avg       0.82      0.81      0.81      2000
weighted avg       0.82      0.81      0.81      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.91

Classification Report:
              precision    recall  f1-score   support

    Negative       0.94      0.88      0.91      1000
    Positive       0.89      0.95      0.92      1000

    accuracy                           0.91      2000
   macro avg       0.92      0.91      0.91      2000
weighted avg       0.92      0.91      0.91      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.81

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.76      0.80      1000
    Positive       0.78      0.85      0.82      1000

    accuracy                           0.81      2000
   macro avg       0.81      0.81      0.81      2000
weighted avg       0.81      0.81      0.81      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.95

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.93      0.95      1000
    Positive       0.93      0.98      0.96      1000

    accuracy                           0.95      2000
   macro avg       0.96      0.96      0.95      2000
weighted avg       0.96      0.95      0.95      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.83

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.79      0.82      1000
    Positive       0.80      0.87      0.84      1000

    accuracy                           0.83      2000
   macro avg       0.83      0.83      0.83      2000
weighted avg       0.83      0.83      0.83      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.95

Classification Report:
              precision    recall  f1-score   support

    Negative       0.96      0.95      0.95      1000
    Positive       0.95      0.96      0.95      1000

    accuracy                           0.95      2000
   macro avg       0.95      0.95      0.95      2000
weighted avg       0.95      0.95      0.95      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.81      0.83      1000
    Positive       0.82      0.87      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.95

Classification Report:
              precision    recall  f1-score   support

    Negative       0.96      0.94      0.95      1000
    Positive       0.94      0.96      0.95      1000

    accuracy                           0.95      2000
   macro avg       0.95      0.95      0.95      2000
weighted avg       0.95      0.95      0.95      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.80      0.83      1000
    Positive       0.82      0.87      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.83

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.83      0.83      1000
    Positive       0.83      0.84      0.83      1000

    accuracy                           0.83      2000
   macro avg       0.83      0.83      0.83      2000
weighted avg       0.83      0.83      0.83      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.81      0.83      1000
    Positive       0.82      0.86      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.81      0.83      1000
    Positive       0.82      0.87      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.93

Classification Report:
              precision    recall  f1-score   support

    Negative       0.95      0.90      0.93      1000
    Positive       0.91      0.95      0.93      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.80      0.83      1000
    Positive       0.81      0.88      0.84      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.92

Classification Report:
              precision    recall  f1-score   support

    Negative       0.95      0.89      0.92      1000
    Positive       0.89      0.95      0.92      1000

    accuracy                           0.92      2000
   macro avg       0.92      0.92      0.92      2000
weighted avg       0.92      0.92      0.92      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.83

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.77      0.82      1000
    Positive       0.80      0.88      0.83      1000

    accuracy                           0.83      2000
   macro avg       0.83      0.83      0.83      2000
weighted avg       0.83      0.83      0.83      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.93

Classification Report:
              precision    recall  f1-score   support

    Negative       0.94      0.92      0.93      1000
    Positive       0.93      0.94      0.94      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.83

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.83      0.83      1000
    Positive       0.83      0.83      0.83      1000

    accuracy                           0.83      2000
   macro avg       0.83      0.83      0.83      2000
weighted avg       0.83      0.83      0.83      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.95      0.96      1000
    Positive       0.95      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.82

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.79      0.82      1000
    Positive       0.80      0.85      0.83      1000

    accuracy                           0.82      2000
   macro avg       0.82      0.82      0.82      2000
weighted avg       0.82      0.82      0.82      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.97

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.95      0.96      1000
    Positive       0.95      0.98      0.97      1000

    accuracy                           0.97      2000
   macro avg       0.97      0.97      0.97      2000
weighted avg       0.97      0.97      0.97      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.83

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.80      0.83      1000
    Positive       0.81      0.87      0.84      1000

    accuracy                           0.83      2000
   macro avg       0.84      0.83      0.83      2000
weighted avg       0.84      0.83      0.83      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.94      0.96      1000
    Positive       0.94      0.98      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.88      0.80      0.84      1000
    Positive       0.82      0.89      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.84      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Random Forest with params {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 10} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model RandomForestClassifier trained successfully with parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 10}

Evaluation on Training Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       1.00      1.00      1.00      1000
    Positive       1.00      1.00      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Random Forest):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 0.1, 'fit_prior': True, 'force_alpha': True} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 0.1, 'fit_prior': True, 'force_alpha': True}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      1.00      1000
    Positive       1.00      0.99      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.80

Classification Report:
              precision    recall  f1-score   support

    Negative       0.77      0.84      0.81      1000
    Positive       0.83      0.75      0.79      1000

    accuracy                           0.80      2000
   macro avg       0.80      0.80      0.80      2000
weighted avg       0.80      0.80      0.80      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 0.1, 'fit_prior': True, 'force_alpha': False} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 0.1, 'fit_prior': True, 'force_alpha': False}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      1.00      1000
    Positive       1.00      0.99      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.80

Classification Report:
              precision    recall  f1-score   support

    Negative       0.77      0.84      0.81      1000
    Positive       0.83      0.75      0.79      1000

    accuracy                           0.80      2000
   macro avg       0.80      0.80      0.80      2000
weighted avg       0.80      0.80      0.80      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 0.1, 'fit_prior': False, 'force_alpha': True} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 0.1, 'fit_prior': False, 'force_alpha': True}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      1.00      1000
    Positive       1.00      0.99      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.80

Classification Report:
              precision    recall  f1-score   support

    Negative       0.77      0.84      0.81      1000
    Positive       0.83      0.75      0.79      1000

    accuracy                           0.80      2000
   macro avg       0.80      0.80      0.80      2000
weighted avg       0.80      0.80      0.80      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 0.1, 'fit_prior': False, 'force_alpha': False} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 0.1, 'fit_prior': False, 'force_alpha': False}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 1.00

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      1.00      1000
    Positive       1.00      0.99      1.00      1000

    accuracy                           1.00      2000
   macro avg       1.00      1.00      1.00      2000
weighted avg       1.00      1.00      1.00      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.80

Classification Report:
              precision    recall  f1-score   support

    Negative       0.77      0.84      0.81      1000
    Positive       0.83      0.75      0.79      1000

    accuracy                           0.80      2000
   macro avg       0.80      0.80      0.80      2000
weighted avg       0.80      0.80      0.80      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 1.0, 'fit_prior': True, 'force_alpha': True} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 1.0, 'fit_prior': True, 'force_alpha': True}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.99      0.98      1000
    Positive       0.99      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.85      0.84      1000
    Positive       0.85      0.82      0.83      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 1.0, 'fit_prior': True, 'force_alpha': False} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 1.0, 'fit_prior': True, 'force_alpha': False}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.99      0.98      1000
    Positive       0.99      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.85      0.84      1000
    Positive       0.85      0.82      0.83      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 1.0, 'fit_prior': False, 'force_alpha': True} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 1.0, 'fit_prior': False, 'force_alpha': True}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.99      0.98      1000
    Positive       0.99      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.85      0.84      1000
    Positive       0.85      0.82      0.83      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 1.0, 'fit_prior': False, 'force_alpha': False} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 1.0, 'fit_prior': False, 'force_alpha': False}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.99      0.98      1000
    Positive       0.99      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.84

Classification Report:
              precision    recall  f1-score   support

    Negative       0.83      0.85      0.84      1000
    Positive       0.85      0.82      0.83      1000

    accuracy                           0.84      2000
   macro avg       0.84      0.84      0.84      2000
weighted avg       0.84      0.84      0.84      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 2.0, 'fit_prior': True, 'force_alpha': True} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 2.0, 'fit_prior': True, 'force_alpha': True}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.97

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.97      0.97      1000
    Positive       0.97      0.97      0.97      1000

    accuracy                           0.97      2000
   macro avg       0.97      0.97      0.97      2000
weighted avg       0.97      0.97      0.97      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.86      0.85      1000
    Positive       0.85      0.83      0.84      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 2.0, 'fit_prior': True, 'force_alpha': False} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 2.0, 'fit_prior': True, 'force_alpha': False}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.97

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.97      0.97      1000
    Positive       0.97      0.97      0.97      1000

    accuracy                           0.97      2000
   macro avg       0.97      0.97      0.97      2000
weighted avg       0.97      0.97      0.97      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.86      0.85      1000
    Positive       0.85      0.83      0.84      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 2.0, 'fit_prior': False, 'force_alpha': True} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 2.0, 'fit_prior': False, 'force_alpha': True}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.97

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.97      0.97      1000
    Positive       0.97      0.97      0.97      1000

    accuracy                           0.97      2000
   macro avg       0.97      0.97      0.97      2000
weighted avg       0.97      0.97      0.97      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.86      0.85      1000
    Positive       0.85      0.83      0.84      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Naive Bayes with params {'alpha': 2.0, 'fit_prior': False, 'force_alpha': False} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model MultinomialNB trained successfully with parameters: {'alpha': 2.0, 'fit_prior': False, 'force_alpha': False}

Evaluation on Training Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.97

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.97      0.97      1000
    Positive       0.97      0.97      0.97      1000

    accuracy                           0.97      2000
   macro avg       0.97      0.97      0.97      2000
weighted avg       0.97      0.97      0.97      2000


Evaluation on Test Set (Naive Bayes):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.86      0.85      1000
    Positive       0.85      0.83      0.84      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'liblinear', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'liblinear', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'liblinear', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'liblinear', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'liblinear', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'liblinear', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'saga', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'saga', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'saga', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'saga', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 0.5, 'solver': 'saga', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 0.5, 'solver': 'saga', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    Negative       0.97      0.96      0.96      1000
    Positive       0.96      0.97      0.96      1000

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.87      0.83      0.85      1000
    Positive       0.84      0.87      0.86      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'liblinear', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'liblinear', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.84      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'liblinear', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'liblinear', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.84      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'liblinear', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'liblinear', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.84      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.85      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.85      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.85      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'saga', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'saga', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.84      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'saga', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'saga', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.84      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 1.0, 'solver': 'saga', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 1.0, 'solver': 'saga', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.98

Classification Report:
              precision    recall  f1-score   support

    Negative       0.98      0.97      0.98      1000
    Positive       0.97      0.98      0.98      1000

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.86      0.84      0.85      1000
    Positive       0.85      0.86      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'liblinear', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'liblinear', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.86

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.86      1000

    accuracy                           0.86      2000
   macro avg       0.86      0.86      0.86      2000
weighted avg       0.86      0.86      0.86      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'liblinear', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'liblinear', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.86

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.86      1000

    accuracy                           0.86      2000
   macro avg       0.86      0.86      0.86      2000
weighted avg       0.86      0.86      0.86      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'liblinear', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'liblinear', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.86

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.86      1000

    accuracy                           0.86      2000
   macro avg       0.86      0.86      0.86      2000
weighted avg       0.86      0.86      0.86      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.85

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'saga', 'max_iter': 1000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'saga', 'max_iter': 1000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.86

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.86      1000

    accuracy                           0.86      2000
   macro avg       0.86      0.86      0.86      2000
weighted avg       0.86      0.86      0.86      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'saga', 'max_iter': 100} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'saga', 'max_iter': 100}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.86

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.86      1000

    accuracy                           0.86      2000
   macro avg       0.86      0.86      0.86      2000
weighted avg       0.86      0.86      0.86      2000


========== Training and Evaluating Logistic Regression with params {'C': 2.0, 'solver': 'saga', 'max_iter': 10000} ==========
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
鉁?Model LogisticRegression trained successfully with parameters: {'C': 2.0, 'solver': 'saga', 'max_iter': 10000}

Evaluation on Training Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.99

Classification Report:
              precision    recall  f1-score   support

    Negative       0.99      1.00      0.99      1000
    Positive       1.00      0.99      0.99      1000

    accuracy                           0.99      2000
   macro avg       0.99      0.99      0.99      2000
weighted avg       0.99      0.99      0.99      2000


Evaluation on Test Set (Logistic Regression):
鉁旓笍 Ograniczono liczb臋 plik贸w w neg do 1000.
鉁旓笍 Ograniczono liczb臋 plik贸w w pos do 1000.
鉁旓笍 Wczytano wszystkie etykiety (艂膮cznie: 2000).
Accuracy: 0.86

Classification Report:
              precision    recall  f1-score   support

    Negative       0.85      0.86      0.86      1000
    Positive       0.86      0.85      0.86      1000

    accuracy                           0.86      2000
   macro avg       0.86      0.86      0.86      2000
weighted avg       0.86      0.86      0.86      2000


=== Summary of Results ===
                  Model                                         Parameters  \
0             LinearSVC      {'C': 0.5, 'max_iter': 1000, 'loss': 'hinge'}   
1             LinearSVC  {'C': 0.5, 'max_iter': 1000, 'loss': 'squared_...   
2             LinearSVC       {'C': 0.5, 'max_iter': 100, 'loss': 'hinge'}   
3             LinearSVC  {'C': 0.5, 'max_iter': 100, 'loss': 'squared_h...   
4             LinearSVC     {'C': 0.5, 'max_iter': 10000, 'loss': 'hinge'}   
5             LinearSVC  {'C': 0.5, 'max_iter': 10000, 'loss': 'squared...   
6             LinearSVC      {'C': 1.0, 'max_iter': 1000, 'loss': 'hinge'}   
7             LinearSVC  {'C': 1.0, 'max_iter': 1000, 'loss': 'squared_...   
8             LinearSVC       {'C': 1.0, 'max_iter': 100, 'loss': 'hinge'}   
9             LinearSVC  {'C': 1.0, 'max_iter': 100, 'loss': 'squared_h...   
10            LinearSVC     {'C': 1.0, 'max_iter': 10000, 'loss': 'hinge'}   
11            LinearSVC  {'C': 1.0, 'max_iter': 10000, 'loss': 'squared...   
12            LinearSVC      {'C': 2.0, 'max_iter': 1000, 'loss': 'hinge'}   
13            LinearSVC  {'C': 2.0, 'max_iter': 1000, 'loss': 'squared_...   
14            LinearSVC       {'C': 2.0, 'max_iter': 100, 'loss': 'hinge'}   
15            LinearSVC  {'C': 2.0, 'max_iter': 100, 'loss': 'squared_h...   
16            LinearSVC     {'C': 2.0, 'max_iter': 10000, 'loss': 'hinge'}   
17            LinearSVC  {'C': 2.0, 'max_iter': 10000, 'loss': 'squared...   
18        Random Forest  {'n_estimators': 50, 'max_depth': 5, 'min_samp...   
19        Random Forest  {'n_estimators': 50, 'max_depth': 5, 'min_samp...   
20        Random Forest  {'n_estimators': 50, 'max_depth': 5, 'min_samp...   
21        Random Forest  {'n_estimators': 50, 'max_depth': 10, 'min_sam...   
22        Random Forest  {'n_estimators': 50, 'max_depth': 10, 'min_sam...   
23        Random Forest  {'n_estimators': 50, 'max_depth': 10, 'min_sam...   
24        Random Forest  {'n_estimators': 50, 'max_depth': None, 'min_s...   
25        Random Forest  {'n_estimators': 50, 'max_depth': None, 'min_s...   
26        Random Forest  {'n_estimators': 50, 'max_depth': None, 'min_s...   
27        Random Forest  {'n_estimators': 100, 'max_depth': 5, 'min_sam...   
28        Random Forest  {'n_estimators': 100, 'max_depth': 5, 'min_sam...   
29        Random Forest  {'n_estimators': 100, 'max_depth': 5, 'min_sam...   
30        Random Forest  {'n_estimators': 100, 'max_depth': 10, 'min_sa...   
31        Random Forest  {'n_estimators': 100, 'max_depth': 10, 'min_sa...   
32        Random Forest  {'n_estimators': 100, 'max_depth': 10, 'min_sa...   
33        Random Forest  {'n_estimators': 100, 'max_depth': None, 'min_...   
34        Random Forest  {'n_estimators': 100, 'max_depth': None, 'min_...   
35        Random Forest  {'n_estimators': 100, 'max_depth': None, 'min_...   
36        Random Forest  {'n_estimators': 200, 'max_depth': 5, 'min_sam...   
37        Random Forest  {'n_estimators': 200, 'max_depth': 5, 'min_sam...   
38        Random Forest  {'n_estimators': 200, 'max_depth': 5, 'min_sam...   
39        Random Forest  {'n_estimators': 200, 'max_depth': 10, 'min_sa...   
40        Random Forest  {'n_estimators': 200, 'max_depth': 10, 'min_sa...   
41        Random Forest  {'n_estimators': 200, 'max_depth': 10, 'min_sa...   
42        Random Forest  {'n_estimators': 200, 'max_depth': None, 'min_...   
43        Random Forest  {'n_estimators': 200, 'max_depth': None, 'min_...   
44        Random Forest  {'n_estimators': 200, 'max_depth': None, 'min_...   
45          Naive Bayes  {'alpha': 0.1, 'fit_prior': True, 'force_alpha...   
46          Naive Bayes  {'alpha': 0.1, 'fit_prior': True, 'force_alpha...   
47          Naive Bayes  {'alpha': 0.1, 'fit_prior': False, 'force_alph...   
48          Naive Bayes  {'alpha': 0.1, 'fit_prior': False, 'force_alph...   
49          Naive Bayes  {'alpha': 1.0, 'fit_prior': True, 'force_alpha...   
50          Naive Bayes  {'alpha': 1.0, 'fit_prior': True, 'force_alpha...   
51          Naive Bayes  {'alpha': 1.0, 'fit_prior': False, 'force_alph...   
52          Naive Bayes  {'alpha': 1.0, 'fit_prior': False, 'force_alph...   
53          Naive Bayes  {'alpha': 2.0, 'fit_prior': True, 'force_alpha...   
54          Naive Bayes  {'alpha': 2.0, 'fit_prior': True, 'force_alpha...   
55          Naive Bayes  {'alpha': 2.0, 'fit_prior': False, 'force_alph...   
56          Naive Bayes  {'alpha': 2.0, 'fit_prior': False, 'force_alph...   
57  Logistic Regression  {'C': 0.5, 'solver': 'liblinear', 'max_iter': ...   
58  Logistic Regression  {'C': 0.5, 'solver': 'liblinear', 'max_iter': ...   
59  Logistic Regression  {'C': 0.5, 'solver': 'liblinear', 'max_iter': ...   
60  Logistic Regression    {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 1000}   
61  Logistic Regression     {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 100}   
62  Logistic Regression   {'C': 0.5, 'solver': 'lbfgs', 'max_iter': 10000}   
63  Logistic Regression     {'C': 0.5, 'solver': 'saga', 'max_iter': 1000}   
64  Logistic Regression      {'C': 0.5, 'solver': 'saga', 'max_iter': 100}   
65  Logistic Regression    {'C': 0.5, 'solver': 'saga', 'max_iter': 10000}   
66  Logistic Regression  {'C': 1.0, 'solver': 'liblinear', 'max_iter': ...   
67  Logistic Regression  {'C': 1.0, 'solver': 'liblinear', 'max_iter': ...   
68  Logistic Regression  {'C': 1.0, 'solver': 'liblinear', 'max_iter': ...   
69  Logistic Regression    {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 1000}   
70  Logistic Regression     {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 100}   
71  Logistic Regression   {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 10000}   
72  Logistic Regression     {'C': 1.0, 'solver': 'saga', 'max_iter': 1000}   
73  Logistic Regression      {'C': 1.0, 'solver': 'saga', 'max_iter': 100}   
74  Logistic Regression    {'C': 1.0, 'solver': 'saga', 'max_iter': 10000}   
75  Logistic Regression  {'C': 2.0, 'solver': 'liblinear', 'max_iter': ...   
76  Logistic Regression  {'C': 2.0, 'solver': 'liblinear', 'max_iter': ...   
77  Logistic Regression  {'C': 2.0, 'solver': 'liblinear', 'max_iter': ...   
78  Logistic Regression    {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 1000}   
79  Logistic Regression     {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 100}   
80  Logistic Regression   {'C': 2.0, 'solver': 'lbfgs', 'max_iter': 10000}   
81  Logistic Regression     {'C': 2.0, 'solver': 'saga', 'max_iter': 1000}   
82  Logistic Regression      {'C': 2.0, 'solver': 'saga', 'max_iter': 100}   
83  Logistic Regression    {'C': 2.0, 'solver': 'saga', 'max_iter': 10000}   

    Train Accuracy  Test Accuracy  
0           0.9855         0.8480  
1           0.9980         0.8395  
2           0.9855         0.8480  
3           0.9980         0.8395  
4           0.9855         0.8480  
5           0.9980         0.8395  
6           0.9970         0.8210  
7           1.0000         0.8245  
8           0.9970         0.8210  
9           1.0000         0.8245  
10          0.9970         0.8205  
11          1.0000         0.8245  
12          0.9995         0.8095  
13          1.0000         0.8165  
14          0.9995         0.8095  
15          1.0000         0.8165  
16          0.9995         0.8095  
17          1.0000         0.8165  
18          0.9035         0.7970  
19          0.8810         0.7785  
20          0.8685         0.7800  
21          0.9450         0.8190  
22          0.9315         0.8130  
23          0.9345         0.8185  
24          1.0000         0.8360  
25          1.0000         0.8295  
26          1.0000         0.8325  
27          0.9090         0.8135  
28          0.9200         0.8150  
29          0.9135         0.8090  
30          0.9550         0.8290  
31          0.9540         0.8385  
32          0.9530         0.8360  
33          1.0000         0.8340  
34          1.0000         0.8355  
35          1.0000         0.8380  
36          0.9290         0.8385  
37          0.9200         0.8260  
38          0.9345         0.8270  
39          0.9575         0.8205  
40          0.9655         0.8345  
41          0.9615         0.8465  
42          1.0000         0.8535  
43          1.0000         0.8530  
44          1.0000         0.8525  
45          0.9960         0.7965  
46          0.9960         0.7965  
47          0.9960         0.7965  
48          0.9960         0.7965  
49          0.9845         0.8370  
50          0.9845         0.8370  
51          0.9845         0.8370  
52          0.9845         0.8370  
53          0.9740         0.8460  
54          0.9740         0.8460  
55          0.9740         0.8460  
56          0.9740         0.8460  
57          0.9625         0.8535  
58          0.9625         0.8535  
59          0.9625         0.8535  
60          0.9625         0.8535  
61          0.9625         0.8535  
62          0.9625         0.8535  
63          0.9625         0.8535  
64          0.9625         0.8535  
65          0.9625         0.8535  
66          0.9765         0.8520  
67          0.9765         0.8520  
68          0.9765         0.8520  
69          0.9765         0.8530  
70          0.9765         0.8530  
71          0.9765         0.8530  
72          0.9765         0.8520  
73          0.9765         0.8520  
74          0.9765         0.8520  
75          0.9945         0.8555  
76          0.9945         0.8555  
77          0.9945         0.8555  
78          0.9945         0.8545  
79          0.9945         0.8545  
80          0.9945         0.8545  
81          0.9945         0.8560  
82          0.9945         0.8560  
83          0.9945         0.8560  

=== Best Results for Each Model ===

Best result for LinearSVC:
Model                                                 LinearSVC
Parameters        {'C': 0.5, 'max_iter': 1000, 'loss': 'hinge'}
Train Accuracy                                           0.9855
Test Accuracy                                             0.848
Name: 0, dtype: object

Best result for Random Forest:
Model                                                 Random Forest
Parameters        {'n_estimators': 200, 'max_depth': None, 'min_...
Train Accuracy                                                  1.0
Test Accuracy                                                0.8535
Name: 42, dtype: object

Best result for Naive Bayes:
Model                                                   Naive Bayes
Parameters        {'alpha': 2.0, 'fit_prior': True, 'force_alpha...
Train Accuracy                                                0.974
Test Accuracy                                                 0.846
Name: 53, dtype: object

Best result for Logistic Regression:
Model                                       Logistic Regression
Parameters        {'C': 2.0, 'solver': 'saga', 'max_iter': 100}
Train Accuracy                                           0.9945
Test Accuracy                                             0.856
Name: 82, dtype: object

Process finished with exit code 0
